{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2c96d0",
   "metadata": {},
   "source": [
    "# MLP Architecture Comparison UI\n",
    "\n",
    "Use the controls below to set the sample size and MLP architectures. The baseline `[]` is always included. Click **Run** to train, compare, and visualize FP/FN overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9979b1a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_intertwined_spirals, plot_three_datasets_with_fp_fn\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import generate_intertwined_spirals, plot_three_datasets_with_fp_fn\n",
    "from MLPx6 import (\n",
    "    MLP,\n",
    "    MLP_ARCHITECTURES,\n",
    "    prepare_data,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    confusion_counts,\n",
    "    plot_learning_curves,\n",
    " )\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "except ImportError:\n",
    "    widgets = None\n",
    "    display = None\n",
    "    clear_output = None\n",
    "\n",
    "\n",
    "def parse_custom_arch(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    parts = [p.strip() for p in text.split(\",\") if p.strip()]\n",
    "    try:\n",
    "        values = [int(p) for p in parts]\n",
    "    except ValueError:\n",
    "        return None\n",
    "    return values if values else None\n",
    "\n",
    "\n",
    "def collect_fp_fn(model, test_loader):\n",
    "    model.eval()\n",
    "    fp_points = []\n",
    "    fn_points = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            outputs = model(x_batch)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            fp_mask = (predicted == 1) & (y_batch == 0)\n",
    "            fn_mask = (predicted == 0) & (y_batch == 1)\n",
    "            if fp_mask.any():\n",
    "                fp_xy = x_batch[fp_mask.squeeze()]\n",
    "                fp_points.extend([(float(x), float(y)) for x, y in fp_xy.tolist()])\n",
    "            if fn_mask.any():\n",
    "                fn_xy = x_batch[fn_mask.squeeze()]\n",
    "                fn_points.extend([(float(x), float(y)) for x, y in fn_xy.tolist()])\n",
    "    return fp_points, fn_points\n",
    "\n",
    "\n",
    "def compute_metrics(tn, fp, fn, tp):\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
    "    return precision, recall, specificity, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29064b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (845995401.py, line 17)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdisplay(widgets.IntSlider(value=3, min=0, max=10, description=\"Demo:\"))if \"widgets\" not in globals() or widgets is None:\u001b[39m\n                                                                                                                           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, importlib.util, json, os\n",
    "\n",
    "# 1️⃣ Show which interpreter we are using\n",
    "print(\"Using:\", sys.executable)\n",
    "\n",
    "# 2️⃣ Install ipywidgets if missing\n",
    "if importlib.util.find_spec(\"ipywidgets\") is None:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
    "\n",
    "# 3️⃣ Verify import works\n",
    "import ipywidgets as widgets\n",
    "print(\"ipywidgets version:\", widgets.__version__)\n",
    "\n",
    "# 4️⃣ Quick sanity‑check widget\n",
    "from IPython.display import display\n",
    "display(widgets.IntSlider(value=3, min=0, max=10, description=\"Demo:\"))if \"widgets\" not in globals() or widgets is None:\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "        from IPython.display import display, clear_output\n",
    "    except ImportError:\n",
    "        widgets = None\n",
    "        display = None\n",
    "        clear_output = None\n",
    "\n",
    "if widgets is None:\n",
    "    print(\"ipywidgets is not installed. Install it to use the UI.\")\n",
    "else:\n",
    "    arch_options = [\n",
    "        (f\"{name}: {arch}\", name)\n",
    "        for name, arch in MLP_ARCHITECTURES.items()\n",
    "        if name != \"MLP_0\"\n",
    "    ]\n",
    "\n",
    "    n_input = widgets.IntText(value=1000, description=\"Samples\", layout=widgets.Layout(width=\"180px\"))\n",
    "    dataset_input = widgets.Dropdown(\n",
    "        options=[\"RND\", \"CTR\", \"EDGE\"], value=\"RND\", description=\"Dataset\"\n",
    "    )\n",
    "    epochs_input = widgets.IntText(value=100, description=\"Epochs\", layout=widgets.Layout(width=\"180px\"))\n",
    "    lr_input = widgets.FloatText(value=0.001, description=\"LR\", layout=widgets.Layout(width=\"180px\"))\n",
    "    batch_input = widgets.IntText(value=32, description=\"Batch\", layout=widgets.Layout(width=\"180px\"))\n",
    "    arch_select = widgets.SelectMultiple(\n",
    "        options=arch_options,\n",
    "        value=(arch_options[0][1],),\n",
    "        description=\"Architectures\",\n",
    "        layout=widgets.Layout(width=\"380px\", height=\"140px\"),\n",
    "    )\n",
    "    custom_arch_input = widgets.Text(\n",
    "        value=\"\", description=\"Custom\", placeholder=\"e.g., 32,32,16\"\n",
    "    )\n",
    "    run_button = widgets.Button(description=\"Run\", button_style=\"primary\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    controls_row1 = widgets.HBox([n_input, dataset_input, epochs_input, lr_input, batch_input])\n",
    "    controls_row2 = widgets.HBox([arch_select, custom_arch_input])\n",
    "    display(controls_row1, controls_row2, run_button, output)\n",
    "\n",
    "    def on_run(_):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            n = int(n_input.value)\n",
    "            dataset_choice = dataset_input.value\n",
    "            epochs = int(epochs_input.value)\n",
    "            lr = float(lr_input.value)\n",
    "            batch_size = int(batch_input.value)\n",
    "            selected_arch_names = list(arch_select.value)\n",
    "            custom_arch = parse_custom_arch(custom_arch_input.value.strip())\n",
    "            if custom_arch_input.value.strip() and custom_arch is None:\n",
    "                print(\"Invalid custom architecture; ignoring.\")\n",
    "            baseline_arch = (\"BASELINE\", [])\n",
    "            selected_arch = [\n",
    "                (name, MLP_ARCHITECTURES[name])\n",
    "                for name in selected_arch_names\n",
    "                if name in MLP_ARCHITECTURES\n",
    "            ]\n",
    "            if custom_arch is not None:\n",
    "                selected_arch.append((\"CUSTOM\", custom_arch))\n",
    "            if not selected_arch:\n",
    "                print(\"No architectures selected; using baseline only.\")\n",
    "            torch.manual_seed(7)\n",
    "            np.random.seed(7)\n",
    "\n",
    "            rnd_data, ctr_data, edge_data = generate_intertwined_spirals(\n",
    "                n=n, noise_std=0.0, seed=7, sampling_method=\"ALL\", plot=False\n",
    "            )\n",
    "            dataset_storage = {\"RND\": rnd_data, \"CTR\": ctr_data, \"EDGE\": edge_data}\n",
    "            train_loader, val_loader, test_loader = prepare_data(\n",
    "                dataset_storage[dataset_choice],\n",
    "                test_split=0.2,\n",
    "                val_split=0.2,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "            architectures_to_train = [baseline_arch] + selected_arch\n",
    "            train_histories = {}\n",
    "            results = []\n",
    "            for name, hidden_layers in architectures_to_train:\n",
    "                model = MLP(hidden_layers)\n",
    "                trained_model, train_losses, val_losses, test_losses = train_model(\n",
    "                    model, train_loader, val_loader, test_loader, epochs=epochs, lr=lr, verbose=False\n",
    "                )\n",
    "                acc = evaluate_model(trained_model, test_loader)\n",
    "                tn, fp, fn, tp = confusion_counts(trained_model, test_loader)\n",
    "                precision, recall, specificity, f1 = compute_metrics(tn, fp, fn, tp)\n",
    "                total_params = sum(param.numel() for param in trained_model.parameters())\n",
    "                train_histories[name] = {\"train_losses\": train_losses, \"test_losses\": test_losses}\n",
    "                results.append({\n",
    "                    \"name\": name,\n",
    "                    \"arch\": hidden_layers,\n",
    "                    \"acc\": acc,\n",
    "                    \"tn\": tn,\n",
    "                    \"fp\": fp,\n",
    "                    \"fn\": fn,\n",
    "                    \"tp\": tp,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"specificity\": specificity,\n",
    "                    \"f1\": f1,\n",
    "                    \"total_params\": total_params,\n",
    "                    \"model\": trained_model,\n",
    "                })\n",
    "\n",
    "            print(\"=\" * 60)\n",
    "            print(\"RUN PARAMETERS\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Dataset: {dataset_choice}\")\n",
    "            print(f\"n per region: {n} | batch: {batch_size} | epochs: {epochs} | lr: {lr}\")\n",
    "            print(\"Architectures:\")\n",
    "            for item in results:\n",
    "                print(f\"  {item['name']}: {item['arch']}\")\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"MODEL RESULTS\")\n",
    "            print(\"=\" * 60)\n",
    "            for item in results:\n",
    "                print(f\"{item['name']}: arch={item['arch']} | params={item['total_params']}\")\n",
    "                print(\n",
    "                    f\"  Acc={item['acc']*100:.2f}% | \"\n",
    "                    f\"TN={item['tn']} FP={item['fp']} FN={item['fn']} TP={item['tp']}\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"  Precision={item['precision']:.3f} Recall={item['recall']:.3f} \"\n",
    "                    f\"Specificity={item['specificity']:.3f} F1={item['f1']:.3f}\"\n",
    "                )\n",
    "\n",
    "            plot_learning_curves(train_histories, title=f\"Training Loss - {dataset_choice}\")\n",
    "            best_result = max(results, key=lambda r: r[\"acc\"])\n",
    "            fp_points, fn_points = collect_fp_fn(best_result[\"model\"], test_loader)\n",
    "            fp_fn_by_dataset = {\n",
    "                dataset_choice: {\n",
    "                    \"fp\": fp_points,\n",
    "                    \"fn\": fn_points,\n",
    "                    \"model_name\": best_result[\"name\"],\n",
    "                    \"acc\": best_result[\"acc\"],\n",
    "                }\n",
    "            }\n",
    "            plot_three_datasets_with_fp_fn(dataset_storage, fp_fn_by_dataset)\n",
    "\n",
    "    run_button.on_click(on_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab30c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI-driven run happens in the cell above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
